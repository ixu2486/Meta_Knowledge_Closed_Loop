#!/usr/bin/env python3
"""
é›¶æ‹·è²çªç ´å¯¦ç¾ - åŸºæ–¼æ‚¨çš„æ¸¬è©¦ç’°å¢ƒ
è§£æ±ºOpenCLæ•¸æ“šå‚³è¼¸ç“¶é ¸çš„å¯¦éš›æ–¹æ¡ˆ
"""

import time
import numpy as np
import pyopencl as cl
import ctypes
from ctypes import c_void_p, c_size_t, c_uint, c_ulong
import logging
from typing import Dict, List, Tuple, Any
import threading
from concurrent.futures import ThreadPoolExecutor

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ZeroCopyBreathrough:
    """é›¶æ‹·è²çªç ´å¯¦ç¾"""
    
    def __init__(self):
        self.context = None
        self.queue = None
        self.device = None
        self.memory_pool = {}
        self.pool_size = 64 * 1024 * 1024  # 64MB pool
        
    def initialize_opencl(self):
        """åˆå§‹åŒ–OpenCLç’°å¢ƒ"""
        logger.info("ğŸ”§ åˆå§‹åŒ–é›¶æ‹·è²çªç ´ç’°å¢ƒ...")
        
        platforms = cl.get_platforms()
        for platform in platforms:
            try:
                devices = platform.get_devices(device_type=cl.device_type.GPU)
                if devices:
                    self.device = devices[0]
                    self.context = cl.Context([self.device])
                    self.queue = cl.CommandQueue(self.context)
                    break
            except:
                continue
        
        if not self.device:
            raise RuntimeError("æ²’æœ‰æ‰¾åˆ°å¯ç”¨çš„GPUè¨­å‚™")
        
        logger.info(f"âœ… ç’°å¢ƒåˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   è¨­å‚™: {self.device.name}")
        logger.info(f"   æº–å‚™çªç ´æ•¸æ“šå‚³è¼¸ç“¶é ¸...")
        
        # åˆå§‹åŒ–è¨˜æ†¶é«”æ± 
        self._initialize_memory_pool()
    
    def _initialize_memory_pool(self):
        """åˆå§‹åŒ–è¨˜æ†¶é«”æ±  - é åˆ†é…å¤§å¡Šè¨˜æ†¶é«”"""
        logger.info("ğŸŠâ€â™‚ï¸ åˆå§‹åŒ–è¨˜æ†¶é«”æ± ...")
        
        # åˆ†é…ä¸åŒå¤§å°çš„è¨˜æ†¶é«”æ± 
        pool_sizes = [
            (1024, 100),      # 1K * 100
            (10240, 50),      # 10K * 50  
            (102400, 20),     # 100K * 20
            (1024000, 10)     # 1M * 10
        ]
        
        for size, count in pool_sizes:
            self.memory_pool[size] = []
            for i in range(count):
                # åˆ†é…å°é½Šçš„ç³»çµ±è¨˜æ†¶é«”
                host_mem = np.zeros(size, dtype=np.float32)
                
                # ä½¿ç”¨USE_HOST_PTRå‰µå»ºOpenCL bufferï¼Œå¯¦ç¾é›¶æ‹·è²
                cl_buffer = cl.Buffer(
                    self.context, 
                    cl.mem_flags.READ_WRITE | cl.mem_flags.USE_HOST_PTR,
                    hostbuf=host_mem
                )
                
                self.memory_pool[size].append({
                    'host_ptr': host_mem,
                    'cl_buffer': cl_buffer,
                    'in_use': False
                })
        
        logger.info(f"âœ… è¨˜æ†¶é«”æ± åˆå§‹åŒ–å®Œæˆï¼Œé åˆ†é… {sum(count for _, count in pool_sizes)} å€‹buffer")
    
    def get_pool_buffer(self, size: int):
        """å¾è¨˜æ†¶é«”æ± ç²å–buffer"""
        if size not in self.memory_pool:
            # æ‰¾æœ€æ¥è¿‘çš„å¤§å°
            available_sizes = [s for s in self.memory_pool.keys() if s >= size]
            if not available_sizes:
                size = max(self.memory_pool.keys())
            else:
                size = min(available_sizes)
        
        # æ‰¾ç©ºé–’çš„buffer
        for buffer in self.memory_pool[size]:
            if not buffer['in_use']:
                buffer['in_use'] = True
                return buffer
        
        # å¦‚æœæ²’æœ‰ç©ºé–’çš„ï¼Œå‰µå»ºæ–°çš„
        host_mem = np.zeros(size, dtype=np.float32)
        cl_buffer = cl.Buffer(
            self.context,
            cl.mem_flags.READ_WRITE | cl.mem_flags.USE_HOST_PTR,
            hostbuf=host_mem
        )
        buffer = {
            'host_ptr': host_mem,
            'cl_buffer': cl_buffer,
            'in_use': True
        }
        self.memory_pool[size].append(buffer)
        return buffer
    
    def return_pool_buffer(self, buffer):
        """æ­¸é‚„bufferåˆ°è¨˜æ†¶é«”æ± """
        buffer['in_use'] = False
    
    def create_optimized_kernel(self) -> cl.Program:
        """å‰µå»ºå„ªåŒ–çš„kernel"""
        kernel_source = """
        // é‡å°APUå„ªåŒ–çš„kernel
        __kernel void zero_copy_vector_add(
            __global float* a, 
            __global float* b, 
            __global float* result, 
            int n
        ) {
            int idx = get_global_id(0);
            int stride = get_global_size(0);
            
            // å±•é–‹å¾ªç’°ï¼Œæ¸›å°‘åˆ†æ”¯
            for (int i = idx; i < n; i += stride) {
                result[i] = a[i] + b[i];
            }
        }
        
        __kernel void zero_copy_complex_compute(
            __global float* input,
            __global float* output,
            int n
        ) {
            int idx = get_global_id(0);
            int stride = get_global_size(0);
            
            for (int i = idx; i < n; i += stride) {
                float x = input[i];
                // è¤‡é›œè¨ˆç®—ä¾†æ¸¬è©¦çœŸå¯¦å ´æ™¯
                output[i] = sin(x) * cos(x) + sqrt(abs(x)) * 0.5f;
            }
        }
        """
        
        return cl.Program(self.context, kernel_source).build()
    
    def test_zero_copy_performance(self, data_size: int, iterations: int = 5) -> Dict[str, float]:
        """æ¸¬è©¦é›¶æ‹·è²æ€§èƒ½"""
        logger.info(f"ğŸš€ æ¸¬è©¦é›¶æ‹·è²æ€§èƒ½ (å¤§å°: {data_size})")
        
        program = self.create_optimized_kernel()
        kernel = program.zero_copy_vector_add
        
        times = {
            'buffer_acquisition': [],
            'data_preparation': [],
            'kernel_execution': [],
            'result_access': [],
            'buffer_cleanup': [],
            'total': []
        }
        
        for i in range(iterations):
            start_total = time.perf_counter()
            
            # 1. å¾è¨˜æ†¶é«”æ± ç²å–buffer
            start = time.perf_counter()
            buf_a = self.get_pool_buffer(data_size)
            buf_b = self.get_pool_buffer(data_size)
            buf_result = self.get_pool_buffer(data_size)
            times['buffer_acquisition'].append(time.perf_counter() - start)
            
            # 2. ç›´æ¥åœ¨host memoryæº–å‚™æ•¸æ“š (é›¶æ‹·è²ï¼)
            start = time.perf_counter()
            buf_a['host_ptr'][:data_size] = np.random.rand(data_size).astype(np.float32)
            buf_b['host_ptr'][:data_size] = np.random.rand(data_size).astype(np.float32)
            times['data_preparation'].append(time.perf_counter() - start)
            
            # 3. åŸ·è¡Œkernel (GPUç›´æ¥è¨ªå•host memory)
            start = time.perf_counter()
            kernel.set_arg(0, buf_a['cl_buffer'])
            kernel.set_arg(1, buf_b['cl_buffer'])
            kernel.set_arg(2, buf_result['cl_buffer'])
            kernel.set_arg(3, np.int32(data_size))
            
            cl.enqueue_nd_range_kernel(self.queue, kernel, (min(data_size, 1024),), None)
            self.queue.finish()
            times['kernel_execution'].append(time.perf_counter() - start)
            
            # 4. ç›´æ¥è¨ªå•çµæœ (é›¶æ‹·è²ï¼)
            start = time.perf_counter()
            result = buf_result['host_ptr'][:data_size].copy()  # åªæ˜¯ç‚ºäº†æ¨¡æ“¬ä½¿ç”¨
            times['result_access'].append(time.perf_counter() - start)
            
            # 5. æ­¸é‚„buffer
            start = time.perf_counter()
            self.return_pool_buffer(buf_a)
            self.return_pool_buffer(buf_b)
            self.return_pool_buffer(buf_result)
            times['buffer_cleanup'].append(time.perf_counter() - start)
            
            times['total'].append(time.perf_counter() - start_total)
        
        # è¨ˆç®—å¹³å‡å€¼
        avg_times = {key: np.mean(time_list) * 1000 for key, time_list in times.items()}
        
        logger.info(f"   Bufferç²å–: {avg_times['buffer_acquisition']:.3f} ms")
        logger.info(f"   æ•¸æ“šæº–å‚™: {avg_times['data_preparation']:.3f} ms")
        logger.info(f"   KernelåŸ·è¡Œ: {avg_times['kernel_execution']:.3f} ms")
        logger.info(f"   çµæœè¨ªå•: {avg_times['result_access']:.3f} ms")
        logger.info(f"   Bufferæ­¸é‚„: {avg_times['buffer_cleanup']:.3f} ms")
        logger.info(f"   ç¸½æ™‚é–“: {avg_times['total']:.3f} ms")
        
        return avg_times
    
    def test_async_pipeline(self, data_size: int, chunks: int = 4) -> Dict[str, float]:
        """æ¸¬è©¦ç•°æ­¥æµæ°´ç·šè™•ç†"""
        logger.info(f"ğŸ”„ æ¸¬è©¦ç•°æ­¥æµæ°´ç·š (å¤§å°: {data_size}, åˆ†å¡Š: {chunks})")
        
        program = self.create_optimized_kernel()
        kernel = program.zero_copy_complex_compute
        
        chunk_size = data_size // chunks
        
        # å‰µå»ºå¤šå€‹CommandQueueå¯¦ç¾ä¸¦è¡Œ
        queues = [cl.CommandQueue(self.context) for _ in range(min(chunks, 3))]
        
        start_total = time.perf_counter()
        
        # æº–å‚™æ‰€æœ‰æ•¸æ“šå¡Š
        input_data = np.random.rand(data_size).astype(np.float32)
        results = []
        
        def process_chunk(chunk_id, start_idx, end_idx, queue_idx):
            """è™•ç†å–®å€‹æ•¸æ“šå¡Š"""
            queue = queues[queue_idx % len(queues)]
            
            # ç²å–buffer
            input_buf = self.get_pool_buffer(chunk_size)
            output_buf = self.get_pool_buffer(chunk_size)
            
            # æº–å‚™æ•¸æ“š
            chunk_data = input_data[start_idx:end_idx]
            input_buf['host_ptr'][:len(chunk_data)] = chunk_data
            
            # åŸ·è¡Œkernel
            kernel.set_arg(0, input_buf['cl_buffer'])
            kernel.set_arg(1, output_buf['cl_buffer'])
            kernel.set_arg(2, np.int32(len(chunk_data)))
            
            cl.enqueue_nd_range_kernel(queue, kernel, (min(len(chunk_data), 256),), None)
            queue.finish()
            
            # ç²å–çµæœ
            result = output_buf['host_ptr'][:len(chunk_data)].copy()
            
            # æ­¸é‚„buffer
            self.return_pool_buffer(input_buf)
            self.return_pool_buffer(output_buf)
            
            return chunk_id, result
        
        # ä¸¦è¡Œè™•ç†æ‰€æœ‰å¡Š
        with ThreadPoolExecutor(max_workers=chunks) as executor:
            futures = []
            for i in range(chunks):
                start_idx = i * chunk_size
                end_idx = min((i + 1) * chunk_size, data_size)
                future = executor.submit(process_chunk, i, start_idx, end_idx, i)
                futures.append(future)
            
            # æ”¶é›†çµæœ
            for future in futures:
                chunk_id, result = future.result()
                results.append((chunk_id, result))
        
        total_time = (time.perf_counter() - start_total) * 1000
        
        logger.info(f"   æµæ°´ç·šç¸½æ™‚é–“: {total_time:.3f} ms")
        logger.info(f"   è™•ç† {chunks} å€‹å¡Šä¸¦è¡Œå®Œæˆ")
        
        return {'pipeline_total_ms': total_time, 'chunks_processed': chunks}
    
    def run_breakthrough_comparison(self):
        """é‹è¡Œçªç ´æ€§å°æ¯”æ¸¬è©¦"""
        logger.info("ğŸ”¥ é–‹å§‹é›¶æ‹·è²çªç ´å°æ¯”æ¸¬è©¦")
        
        test_sizes = [1024, 10240, 102400, 1024000]
        
        results = {
            'device_info': {
                'name': self.device.name,
                'vendor': self.device.vendor,
                'version': self.device.version
            },
            'zero_copy_tests': {},
            'pipeline_tests': {}
        }
        
        # é›¶æ‹·è²æ¸¬è©¦
        logger.info("\nğŸš€ é›¶æ‹·è²æ€§èƒ½æ¸¬è©¦:")
        for size in test_sizes:
            logger.info(f"\n--- æ¸¬è©¦å¤§å°: {size} å…ƒç´  ({size*4/1024:.1f} KB) ---")
            results['zero_copy_tests'][size] = self.test_zero_copy_performance(size)
        
        # æµæ°´ç·šæ¸¬è©¦
        logger.info("\nğŸ”„ ç•°æ­¥æµæ°´ç·šæ¸¬è©¦:")
        for size in [102400, 1024000]:  # è¼ƒå¤§æ•¸æ“šæ¸¬è©¦æµæ°´ç·š
            logger.info(f"\n--- æµæ°´ç·šå¤§å°: {size} å…ƒç´  ---")
            results['pipeline_tests'][size] = self.test_async_pipeline(size)
        
        return results
    
    def analyze_breakthrough(self, results: Dict[str, Any], baseline_results: Dict[str, Any] = None):
        """åˆ†æçªç ´æ•ˆæœ"""
        logger.info("\n" + "="*80)
        logger.info("ğŸ¯ é›¶æ‹·è²çªç ´æ•ˆæœåˆ†æ")
        logger.info("="*80)
        
        device_info = results['device_info']
        logger.info(f"ğŸ–¥ï¸ æ¸¬è©¦è¨­å‚™: {device_info['name']} ({device_info['vendor']})")
        
        # åˆ†æé›¶æ‹·è²æ€§èƒ½
        logger.info(f"\nğŸš€ é›¶æ‹·è²æ€§èƒ½åˆ†æ:")
        zero_copy_tests = results['zero_copy_tests']
        
        for size, times in zero_copy_tests.items():
            compute_time = times['kernel_execution']
            data_prep_time = times['data_preparation'] + times['result_access']
            management_time = times['buffer_acquisition'] + times['buffer_cleanup']
            
            logger.info(f"\n   æ•¸æ“šå¤§å° {size} ({size*4/1024:.1f} KB):")
            logger.info(f"     è¨ˆç®—æ™‚é–“: {compute_time:.3f} ms ({compute_time/times['total']*100:.1f}%)")
            logger.info(f"     æ•¸æ“šè™•ç†: {data_prep_time:.3f} ms ({data_prep_time/times['total']*100:.1f}%)")
            logger.info(f"     ç®¡ç†é–‹éŠ·: {management_time:.3f} ms ({management_time/times['total']*100:.1f}%)")
            logger.info(f"     ç¸½æ™‚é–“: {times['total']:.3f} ms")
            
            # å¦‚æœæœ‰åŸºæº–æ¸¬è©¦çµæœï¼Œé€²è¡Œå°æ¯”
            if baseline_results and size in baseline_results.get('opencl_buffer_tests', {}):
                baseline = baseline_results['opencl_buffer_tests'][size]
                speedup = baseline['total'] / times['total']
                transfer_eliminated = baseline['data_upload'] + baseline['data_download']
                
                logger.info(f"     ğŸ”¥ æ€§èƒ½æå‡: {speedup:.2f}å€")
                logger.info(f"     ğŸ“ˆ ç¯€çœå‚³è¼¸æ™‚é–“: {transfer_eliminated:.3f} ms")
        
        # åˆ†ææµæ°´ç·šæ•ˆæœ
        if results['pipeline_tests']:
            logger.info(f"\nğŸ”„ ç•°æ­¥æµæ°´ç·šåˆ†æ:")
            for size, pipeline_result in results['pipeline_tests'].items():
                chunks = pipeline_result['chunks_processed']
                total_time = pipeline_result['pipeline_total_ms']
                
                # ä¼°ç®—ä¸²è¡Œè™•ç†æ™‚é–“
                if size in zero_copy_tests:
                    estimated_serial = zero_copy_tests[size]['total'] * chunks
                    parallel_efficiency = estimated_serial / total_time
                    
                    logger.info(f"\n   æ•¸æ“šå¤§å° {size}ï¼Œåˆ† {chunks} å¡Š:")
                    logger.info(f"     ä¸¦è¡Œç¸½æ™‚é–“: {total_time:.3f} ms")
                    logger.info(f"     ä¼°ç®—ä¸²è¡Œæ™‚é–“: {estimated_serial:.3f} ms")
                    logger.info(f"     ä¸¦è¡Œæ•ˆç‡: {parallel_efficiency:.2f}å€")
        
        # çªç ´æ•ˆæœç¸½çµ
        logger.info(f"\nğŸ¯ çªç ´æ•ˆæœç¸½çµ:")
        
        # è¨ˆç®—å¹³å‡æ•¸æ“šè™•ç†å æ¯”
        avg_data_ratio = np.mean([
            (times['data_preparation'] + times['result_access']) / times['total']
            for times in zero_copy_tests.values()
        ])
        
        avg_compute_ratio = np.mean([
            times['kernel_execution'] / times['total']
            for times in zero_copy_tests.values()
        ])
        
        logger.info(f"ğŸ“Š å¹³å‡è¨ˆç®—æ™‚é–“å æ¯”: {avg_compute_ratio*100:.1f}%")
        logger.info(f"ğŸ“Š å¹³å‡æ•¸æ“šè™•ç†å æ¯”: {avg_data_ratio*100:.1f}%")
        
        if avg_compute_ratio > 0.6:
            logger.info("âœ… æˆåŠŸçªç ´ï¼è¨ˆç®—æˆç‚ºä¸»è¦éƒ¨åˆ†ï¼Œæ•¸æ“šå‚³è¼¸ç“¶é ¸å·²è§£æ±º")
        elif avg_compute_ratio > 0.4:
            logger.info("ğŸ”¥ é¡¯è‘—æ”¹å–„ï¼è¨ˆç®—å æ¯”å¤§å¹…æå‡")
        else:
            logger.info("âš ï¸ ä»æœ‰å„ªåŒ–ç©ºé–“ï¼Œç¹¼çºŒèª¿æ•´ç­–ç•¥")
        
        logger.info("ğŸ’¡ é›¶æ‹·è² + è¨˜æ†¶é«”æ±  + ç•°æ­¥æµæ°´ç·š = çªç ´æ•¸æ“šå‚³è¼¸ç“¶é ¸")
        
        return results

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    breakthrough = ZeroCopyBreathrough()
    
    try:
        # åˆå§‹åŒ–
        breakthrough.initialize_opencl()
        
        # é‹è¡Œçªç ´æ¸¬è©¦
        results = breakthrough.run_breakthrough_comparison()
        
        # åˆ†æçµæœ
        breakthrough.analyze_breakthrough(results)
        
        logger.info("\nğŸ‰ é›¶æ‹·è²çªç ´æ¸¬è©¦å®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()